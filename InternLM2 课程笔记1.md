

# InternLM2 模型

开源了7B和12B大小的模型，分别发布了Base、SFT、RLHF各阶段的模型。分别面向不同的应用场景。

在多个维度评估数据价值，使用了高质量的语料数据集，并有针对性的对数据进行了补齐。 

## InternLM2 主要亮点

- 超长上下文，支持20k长度的上下文
- 综合能力提升，在推理、数学、代码能力上提升明显
- 优秀的对话和创作体验，精准指令跟随，丰富的结构化创作，对话充满人文关怀
- 用具调用，支持工具调用，支持搜索、计算、代码解释等
- 拥有数理能力和数据分析能力，内生计算力强大，加入代码解释后数学能力和代码能力进一步提升，并具有数据分析能力

# 全链路开源体系

## 数据

开源书生万卷多模态数据集，数据量高达2TB

融合图片，文本，媒体等模态。数据经过精细的筛选，信息密度高。

我所在的行业是智慧农业行业，在农业行业方面，突出的问题是数据集极度缺乏。无论是用于作物/病虫害识别的图片数据，还是用来训练语言模型的文本数据，都很难在互联网上找到能用的数据，需要自己想办法去搜集。目前公开的文本数据集虽然数量很庞大，比如书生数据集，但是数据的分类还是按照网页数据/论文/书籍/专利等这种通用方式划分的，我认为数据集中的数据集绝对包含农业及其他行业的数据，但是没有进行有效的分类，因此，能够对现有的开源数据集进行另一种维度的划分，比如按照行业进行划分，能够对下游任务的微调产生显著作用，不过如何按照自定义规则有效划分现有数据集也是一个需要解决的问题。

## InternEvo训练框架

支持从8卡到千卡训练，支持Zero、FlashAttention等技术，加速训练。兼容主流Huggingface生态，支持轻量化技术。并且支持开箱即用。

## Xtuner微调框架

支持增量预训练（垂直领域只是）和有监督微调（对话数据）。

支持全残微调和部分参数微调。

适配不同的微调算法，适配Huggingface和ModelScope模型或数据集。

支持自动优化加速，开发者无需关注优化细节。

支持20系以上显卡，可以使用8GB显存微调7B模型。

我自己的使用感受是相比使用Transformers库来训练，既节省显存，又能提高训练速度，我自己的测试发现在使用相同的方式微调时速度甚至能快2到3倍。

## OpenCompass大模型评测

提供中立全面的性能榜单。

CimpassKit：大模型评测全栈工具链。支持数据污染检查、支持丰富的模型推理接入、长文本能力评测、中英文双语主观评测。

建立了开源共享的大模型评测基准社区。

## LMDeploy大模型部署

支持在GPU上部署的全流程解决方案，包括模型轻量化、推理和服务。

支持多种轻量化，包括4bit权重和8bit K/V cache量化。推理引擎支持高效的turbomind引擎和开发友好的pytorch引擎。支持server、gradio和triton服务。支持python、grpc和RESTful推理。

尝试使用Tuibomind和Pytorch推理后发现Turbomind推理要快很多，不过发现一个问题时当前的文档说明有些模糊，比如W8A8的格式似乎不能用Trubomind推理，而W4A16格式只能使用Turbomind推理，文档能够说明这些注意点就更好了。

## Lagent 智能体框架

支持ReAct、ReWoo、AtuoGPT等智能体流程，并灵活支持各种大预言模型，支持丰富的工具。

