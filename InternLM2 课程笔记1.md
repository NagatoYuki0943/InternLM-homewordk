# 开源历史

从去年6月开始，逐步发布了InternLM开源模型，开源多模态数据库，进一步开源对话模型以及发布了千亿大小的模型，直到最近发布了InternLM2模型。

# InternLM2 模型

开源了7B和12B大小的模型，分别发布了Base、SFT、RLHF各阶段的模型。分别面向不同的应用场景。

在多个维度评估数据价值，使用了高质量的语料数据集，并有针对性的对数据进行了补齐。 

## InternLM2 主要亮点

- 超长上下文，支持20k长度的上下文
- 综合能力提升，在推理、数学、代码能力上提升明显
- 优秀的对话和创作体验，精准指令跟随，丰富的结构化创作，对话充满人文关怀
- 用具调用，支持工具调用，支持搜索、计算、代码解释等
- 拥有数理能力和数据分析能力，内生计算力强大，加入代码解释后数学能力和代码能力进一步提升，并具有数据分析能力

# 全链路开源体系

## 数据

开源书生万卷多模态数据集，数据量高达2TB

融合图片，文本，媒体等模态。数据经过精细的筛选，信息密度高。

## InternEvo训练框架

支持从8卡到千卡训练，支持Zero、FlashAttention等技术，加速训练。兼容主流Huggingface生态，支持轻量化技术。并且支持开箱即用

## Xtuner微调框架

支持增量预训练（垂直领域只是）和有监督微调（对话数据）。

支持全残微调和部分参数微调。

适配不同的微调算法，适配Huggingface和ModelScope模型或数据集。

支持自动优化加速，开发者无需关注优化细节。

支持20系以上显卡，可以使用8GB显存微调7B模型。

## OpenCompass大模型评测

提供中立全面的性能榜单。

CimpassKit：大模型评测全栈工具链。支持数据污染检查、支持丰富的模型推理接入、长文本能力评测、中英文双语主观评测。

建立了开源共享的大模型评测基准社区。

## LMDeploy大模型部署

支持在GPU上部署的全流程解决方案，包括模型轻量化、推理和服务。

支持多种轻量化，包括4bit权重和8bit K/V cache量化。推理引擎支持高效的turbomind引擎和开发友好的pytorch引擎。支持server、gradio和triton服务。支持python、grpc和RESTful推理。

## Lagent 智能体框架

支持ReAct、ReWoo、AtuoGPT等智能体流程，并灵活支持各种大预言模型，支持丰富的工具。

